# ğŸ§  RAG-DoczChat

Upload your documents and chat with them using AI â€” in seconds.  
Built for developers, researchers, and teams who want lightning-fast insights from their own files.

---

## ğŸš€ Tech Stack

This project is powered by a modern and scalable AI-first fullstack architecture:

| Layer     | Tech Used                       |
|-----------|----------------------------------|
| ğŸ§© Frontend  | [React](https://react.dev) + [Vite](https://vitejs.dev) |
| âš™ï¸ Backend   | [FastAPI](https://fastapi.tiangolo.com) â€“ blazing fast, Pythonic APIs |
| ğŸ§  AI Engine | [LlamaIndex](https://www.llamaindex.ai/) with [OpenAI](https://platform.openai.com) models |
| ğŸ’¾ Vector DB | `sqlite_vec` â€“ lightweight, local vector search (no Pinecone needed) |
| ğŸ“„ File Support | `.pdf` and `.docx` ingestion with cleaning and embedding |

---

### ğŸ§˜ No External Vector DB Required

> ğŸ’¡ RAG-DoczChat uses a **fully local vector store** via [`sqlite_vec`](https://github.com/asg017/sqlite-vss).  
> That means **no Pinecone, no Chroma, no cloud database** â€” all your document embeddings are stored and queried directly in SQLite.

Perfect for privacy-focused workflows, testing, and offline setups.

---

## âœ¨ Features

- ğŸ“„ Upload PDF or DOCX files
- ğŸ” Vectorize and index documents with OpenAI Embeddings
- ğŸ’¬ Ask questions and receive contextual answers via LLMs
- â™»ï¸ Automatic document cleaning, chunking, and semantic splitting
- âš¡ Fast local semantic search â€” no internet database needed
